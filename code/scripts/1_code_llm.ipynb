{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18e7d21",
   "metadata": {},
   "source": [
    "# LLM for coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d1f7c",
   "metadata": {},
   "source": [
    "In this mini tutorial we will demonstrate how LLM agents can be used effectively for coding.\n",
    "\n",
    "We will use the previous notebook \"0_code_testing\" to see if with a few prompts LLM can reproduce our code and write tests for it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56594a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Data handling packages\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m  \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpynwb\u001b[39;00m  \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Plotting libraries\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Data handling packages\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import pynwb  \n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Set the data root according to OS\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "# Pandas display settings\n",
    "pd.set_option('display.max_columns', None)  # Ensures all columns are shown when printing DataFrames\n",
    "\n",
    "# Inline plotting for Jupyter Notebooks\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b030c9",
   "metadata": {},
   "source": [
    "Let us consider loading in data from the Visual Behavior Neuropixels dataset we saw in a previous day. Specifically, let us load a single experimental session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS \n",
    "    data_root = Path(\"/Volumes/Brain2025/\")\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = Path(\"E:/\")\n",
    "elif ('amzn' in platstring):\n",
    "    # then on CodeOcean\n",
    "    data_root = Path(\"/data/\")\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = Path(\"/media/$USERNAME/Brain2025/\")\n",
    "\n",
    "# pick a session_id and get session data\n",
    "example_sessions = [1139846596, 1152811536, 1069461581 ]\n",
    "this_session = str(example_sessions[0])\n",
    "this_filename = f'ecephys_session_{this_session}.nwb'\n",
    "nwb_path = Path('visual-behavior-neuropixels', 'behavior_ecephys_sessions', this_session, this_filename)\n",
    "\n",
    "# access the session data with pynwb\n",
    "session = pynwb.NWBHDF5IO(data_root / nwb_path).read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b177a6",
   "metadata": {},
   "source": [
    "Let us load in the trial data and metadata about each recorded unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = session.trials.to_dataframe() \n",
    "units_table = session.units.to_dataframe()\n",
    "electrodes_table = session.electrodes.to_dataframe()\n",
    "units_table = units_table.join(electrodes_table, on = 'peak_channel_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4d563",
   "metadata": {},
   "source": [
    "In this metadata, we have important pieces of information such as the amplitude cutoff, inter-spike-interval (ISI) violations ratio, presence ratio, and activity drift of each recorded unit. Generally, we want to filter neurons by these quantities to find \"good\" neurons. For example, consider defining the following thresholds on these quantities below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c814633",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amplitude_cutoff = 0.1\n",
    "max_isi_violations_ratio = 0.5\n",
    "min_presence_ratio = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3364f91",
   "metadata": {},
   "source": [
    "When loading in the trial data for a specific neuron, we can check these quantities with if and print statements to make sure that our criteria are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2728fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_no = 0\n",
    "unit_amplitude_cutoff = units_table.iloc[id_no]['amplitude_cutoff']\n",
    "unit_isi_violations_ratio = units_table.iloc[id_no]['isi_violations']\n",
    "unit_presence_ratio = units_table.iloc[id_no]['presence_ratio']\n",
    "\n",
    "if not unit_amplitude_cutoff <= max_amplitude_cutoff:\n",
    "    print(f'Unit amplitude cutoff is {unit_amplitude_cutoff}, must be <= {max_amplitude_cutoff}')\n",
    "if not unit_isi_violations_ratio <= max_isi_violations_ratio:\n",
    "    print(f'ISI Violations ratio is {unit_isi_violations_ratio}, must be <= {max_isi_violations_ratio}')\n",
    "if not unit_presence_ratio >= min_presence_ratio:\n",
    "    print(f'Presence ratio is {unit_presence_ratio}, must be >= {min_presence_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdf3ec",
   "metadata": {},
   "source": [
    "Alternatively, we can use assert statements instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_no = 0\n",
    "unit_amplitude_cutoff = units_table.iloc[id_no]['amplitude_cutoff']\n",
    "unit_isi_violations_ratio = units_table.iloc[id_no]['isi_violations']\n",
    "unit_presence_ratio = units_table.iloc[id_no]['presence_ratio']\n",
    "\n",
    "assert unit_amplitude_cutoff <= max_amplitude_cutoff, f'Unit amplitude cutoff is {unit_amplitude_cutoff}, must be <= {max_amplitude_cutoff}'\n",
    "assert unit_isi_violations_ratio <= max_isi_violations_ratio, f'ISI Violations ratio is {unit_isi_violations_ratio}, must be <= {max_isi_violations_ratio}'\n",
    "assert unit_presence_ratio >= min_presence_ratio, f'Presence ratio is {unit_presence_ratio}, must be >= {min_presence_ratio}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe31014",
   "metadata": {},
   "source": [
    "\n",
    "### Let us try to reproduce some parts using ChatGPT UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8babea",
   "metadata": {},
   "source": [
    "Try the following prompt:\n",
    "\n",
    "```\"Given a session, load the metadata—specifically, the trials and units—into separate DataFrames.\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbec431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b41df3",
   "metadata": {},
   "source": [
    "Before accepting the result, evaluate what went wrong. Did we give too little information? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6874273",
   "metadata": {},
   "source": [
    "Try this prompt:\n",
    "\n",
    "```\"You are a neuroscientist helping me analyze data from a recent experiment. The data is organized into multiple sessions, each of which can be loaded using: `session = pynwb.NWBHDF5IO(nwb_path).read()`. From each session, I need to extract metadata—specifically, trials and units—and convert them into separate pandas DataFrames. Write a Python script to accomplish this.\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777856eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4aeca3",
   "metadata": {},
   "source": [
    "Notice how much more specific this prompt is—you can refine it even further. Try the following:\n",
    "\n",
    "```\"You are a neuroscientist helping me analyze data from a recent experiment. The data is organized into multiple sessions, each of which can be loaded with: `session = pynwb.NWBHDF5IO(nwb_path).read()`. I need to extract metadata from a session—specifically, trials and units—and convert them into separate pandas DataFrames. Assume the session is already loaded. Write a concise Python script that performs this task. Do not save the DataFrames to CSV. Return only the script, with no additional explanation.\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84848fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0633aca",
   "metadata": {},
   "source": [
    "Discuss: Can you think of a shorter prompt to produce the same or similar result? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f8c98",
   "metadata": {},
   "source": [
    "\n",
    "### If you are using Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3dfb5",
   "metadata": {},
   "source": [
    "Let’s begin with a simple example. Following the logic from the previous notebook, our goal is to extract session metadata and organize it into DataFrames.\n",
    "\n",
    "Try the following prompt:\n",
    "\n",
    "```\"Given a session, load the metadata—specifically, the trials and units—into separate DataFrames.\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a2f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d8a4fc3",
   "metadata": {},
   "source": [
    "Discuss: Why does this prompt work well with GitHub Copilot but not as effectively in the ChatGPT UI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bfee0",
   "metadata": {},
   "source": [
    "With Copilot, short and specific code-related instructions often lead to immediate and relevant completions, since it's optimized for in-context code generation. Let's test this difference by attempting a practical example: generating a function and then writing a test for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28d1e9",
   "metadata": {},
   "source": [
    " \n",
    "We’ll start by providing only the function description and see if Copilot can infer and generate the correct implementation. Try the following prompt:\n",
    "\n",
    "```\"Generate a function called `make_psth` with the following behavior: The function should compute a Peri-Stimulus Time Histogram (PSTH).```\n",
    "\n",
    "```Parameters:```\n",
    "   - spike_times: array-like, timestamps of all spikes (in seconds)\n",
    "   - stim_times: array-like, timestamps of stimulus onsets (in seconds)\n",
    "   - pre_window: float, time before stimulus to include in the PSTH (seconds)\n",
    "   - post_window: float, time after stimulus to include in the PSTH (seconds)\n",
    "   - bin_size: float, width of each time bin (seconds)\n",
    "\n",
    "```Returns:```\n",
    "   - firing_rates: 2D NumPy array of firing rates (shape: trials × bins)\n",
    "   - bin_centers: 1D NumPy array of bin center times (relative to stimulus onset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14eae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54624e04",
   "metadata": {},
   "source": [
    "How can we verify that this function works as intended?\n",
    "One way is to write a test to ensure that make_psth executes properly and returns meaningful output. Try the following prompt:\n",
    "\n",
    "```\"Generate a test to ensure the function `make_psth` runs correctly and returns meaningful results.\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76db30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "037bc3c6",
   "metadata": {},
   "source": [
    "How do you know the test result is actually meaningful? Compare the result with a person sitting next to you. You should _always_ go back and verify the output yourself—never assume it's correct just because it runs.\n",
    "\n",
    "Alternatively, for smaller code blocks or quick autocompletions, you can use Copilot to assist with implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574ab9c",
   "metadata": {},
   "source": [
    "Exercise. Rewrite the function above using autocomplete. Make sure to check every line the Copilot generates for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f33a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
